# --- START OF FILE app/face_comparison.py ---
import streamlit as st
import cv2
import numpy as np
from utils import resize_image_for_display, INSIGHTFACE_AVAILABLE  # –ò–º–ø–æ—Ä—Ç–∏ –æ—Ç utils.py
# MAX_DISPLAY_DIM –∏ INSIGHTFACE_THRESHOLD —â–µ —Å–µ –ø–æ–¥–∞–¥–∞—Ç –∫–∞—Ç–æ –∞—Ä–≥—É–º–µ–Ω—Ç–∏

# sklearn.metrics.pairwise.cosine_similarity —Å–µ –∏–º–ø–æ—Ä—Ç–∏—Ä–∞ —É—Å–ª–æ–≤–Ω–æ –ø–æ-–¥–æ–ª—É


def render_page(INSIGHTFACE_AVAILABLE, insightface_model_app, MAX_DISPLAY_DIM, INSIGHTFACE_THRESHOLD):
    st.header("2. –°—Ä–∞–≤–Ω—è–≤–∞–Ω–µ –Ω–∞ –¥–≤–µ –ª–∏—Ü–∞ (Cosine Similarity —Å InsightFace)")

    if not INSIGHTFACE_AVAILABLE:
        st.error("–ë–∏–±–ª–∏–æ—Ç–µ–∫–∏—Ç–µ 'insightface' –∏–ª–∏ 'scikit-learn' –Ω–µ —Å–∞ –∏–Ω—Å—Ç–∞–ª–∏—Ä–∞–Ω–∏. –¢–∞–∑–∏ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–Ω–æ—Å—Ç –Ω–µ –µ –¥–æ—Å—Ç—ä–ø–Ω–∞. –ú–æ–ª—è, –∏–Ω—Å—Ç–∞–ª–∏—Ä–∞–π—Ç–µ –≥–∏: `pip install insightface onnxruntime scikit-learn`")
        st.stop()

    if insightface_model_app is None:
        st.error("InsightFace –º–æ–¥–µ–ª—ä—Ç –Ω–µ –µ –∑–∞—Ä–µ–¥–µ–Ω. –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–Ω–æ—Å—Ç—Ç–∞ –Ω–µ –µ –¥–æ—Å—Ç—ä–ø–Ω–∞.")
        st.stop()

    # –£—Å–ª–æ–≤–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–∞–Ω–µ –Ω–∞ cosine_similarity
    if INSIGHTFACE_AVAILABLE:
        from sklearn.metrics.pairwise import cosine_similarity

    col1, col2 = st.columns(2)
    with col1:
        uploaded_img1_file = st.file_uploader(
            "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ 1:", type=["jpg", "jpeg", "png"], key="insightface_img1_module")
    with col2:
        uploaded_img2_file = st.file_uploader(
            "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ 2:", type=["jpg", "jpeg", "png"], key="insightface_img2_module")

    def get_face_embedding_and_draw_insight(image_file, img_identifier_str, insight_app_model_instance):
        # –¢–∞–∑–∏ —Ñ—É–Ω–∫—Ü–∏—è —Å–µ –∏–∑–≤–∏–∫–≤–∞ —Å–∞–º–æ –∞–∫–æ image_file –Ω–µ –µ None
        file_bytes_img = np.asarray(
            bytearray(image_file.read()), dtype=np.uint8)
        img_cv_original_bgr = cv2.imdecode(file_bytes_img, cv2.IMREAD_COLOR)

        if img_cv_original_bgr is None:
            st.warning(
                f"–ù–µ—É—Å–ø–µ—à–Ω–æ –∑–∞—Ä–µ–∂–¥–∞–Ω–µ –Ω–∞ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {img_identifier_str}.")
            return None, None, image_file.name

        faces = insight_app_model_instance.get(img_cv_original_bgr)
        img_cv_annotated_bgr = img_cv_original_bgr.copy()

        if not faces:
            st.info(
                f"–ù–µ —Å–∞ –Ω–∞–º–µ—Ä–µ–Ω–∏ –ª–∏—Ü–∞ –Ω–∞ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {img_identifier_str} ({image_file.name}).")
            return None, img_cv_annotated_bgr, image_file.name

        main_face = faces[0]  # –ò–∑–ø–æ–ª–∑–≤–∞–º–µ –ø—ä—Ä–≤–æ—Ç–æ –Ω–∞–º–µ—Ä–µ–Ω–æ –ª–∏—Ü–µ
        if len(faces) > 1:
            st.caption(
                f"–ù–∞–º–µ—Ä–µ–Ω–∏ {len(faces)} –ª–∏—Ü–∞ –≤ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {img_identifier_str}, –∏–∑–ø–æ–ª–∑–≤–∞ —Å–µ –ø—ä—Ä–≤–æ—Ç–æ.")

        bbox = main_face.bbox.astype(int)
        cv2.rectangle(img_cv_annotated_bgr,
                      (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 0), 2)
        embedding = main_face.embedding
        return embedding, img_cv_annotated_bgr, image_file.name

    if uploaded_img1_file and uploaded_img2_file:
        if st.button("üöÄ –°—Ä–∞–≤–Ω–∏ –ª–∏—Ü–∞—Ç–∞ (InsightFace)", key="compare_faces_insightface_btn"):
            with st.spinner("–û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ç–∞ –∏ –∏–∑—á–∏—Å–ª—è–≤–∞–Ω–µ –Ω–∞ —Å—Ö–æ–¥—Å—Ç–≤–æ..."):
                embedding1, img1_processed_bgr, filename1 = get_face_embedding_and_draw_insight(
                    uploaded_img1_file, "1", insightface_model_app)
                embedding2, img2_processed_bgr, filename2 = get_face_embedding_and_draw_insight(
                    uploaded_img2_file, "2", insightface_model_app)

                col_disp1, col_disp2 = st.columns(2)
                display_dim_comparison = MAX_DISPLAY_DIM // 2 + 100
                if display_dim_comparison > MAX_DISPLAY_DIM:
                    display_dim_comparison = MAX_DISPLAY_DIM

                if img1_processed_bgr is not None:
                    with col_disp1:
                        resized_img1_bgr = resize_image_for_display(
                            img1_processed_bgr, display_dim_comparison)
                        resized_img1_rgb = cv2.cvtColor(
                            resized_img1_bgr, cv2.COLOR_BGR2RGB)
                        st.image(
                            resized_img1_rgb, caption=f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ 1: {filename1}", use_column_width='auto')

                if img2_processed_bgr is not None:
                    with col_disp2:
                        resized_img2_bgr = resize_image_for_display(
                            img2_processed_bgr, display_dim_comparison)
                        resized_img2_rgb = cv2.cvtColor(
                            resized_img2_bgr, cv2.COLOR_BGR2RGB)
                        st.image(
                            resized_img2_rgb, caption=f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ 2: {filename2}", use_column_width='auto')

                if embedding1 is not None and embedding2 is not None:
                    similarity_score = cosine_similarity(
                        embedding1.reshape(1, -1), embedding2.reshape(1, -1))[0][0]
                    st.subheader(f"–†–µ–∑—É–ª—Ç–∞—Ç –æ—Ç —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ—Ç–æ:")
                    st.metric(label="Cosine Similarity",
                              value=f"{similarity_score:.4f}")

                    if similarity_score >= INSIGHTFACE_THRESHOLD:
                        st.success(
                            f"–õ–∏—Ü–∞—Ç–∞ —Å–∞ –í–ï–†–û–Ø–¢–ù–û –Ω–∞ –µ–¥–∏–Ω –∏ —Å—ä—â–∏ —á–æ–≤–µ–∫ (—Å—Ö–æ–¥—Å—Ç–≤–æ >= {INSIGHTFACE_THRESHOLD}).")
                    else:
                        st.warning(
                            f"–õ–∏—Ü–∞—Ç–∞ —Å–∞ –í–ï–†–û–Ø–¢–ù–û –Ω–∞ —Ä–∞–∑–ª–∏—á–Ω–∏ —Ö–æ—Ä–∞ (—Å—Ö–æ–¥—Å—Ç–≤–æ < {INSIGHTFACE_THRESHOLD}).")
                    st.caption(
                        f"(–ò–∑–ø–æ–ª–∑–≤–∞–Ω –ø—Ä–∞–≥: {INSIGHTFACE_THRESHOLD} –∑–∞ –º–æ–¥–µ–ª 'buffalo_l'. –°—Ç–æ–π–Ω–æ—Å—Ç–∏—Ç–µ —Å–∞ –º–µ–∂–¥—É -1 –∏ 1. –ü–æ-–≤–∏—Å–æ–∫–∞ = –ø–æ-–≥–æ–ª—è–º–æ —Å—Ö–æ–¥—Å—Ç–≤–æ.)")
                elif (uploaded_img1_file and uploaded_img2_file) and (embedding1 is None or embedding2 is None):
                    st.error(
                        "–ù–µ –º–æ–∂–∞ –¥–∞ —Å–µ –∏–∑–≤–ª–µ—á–µ –ª–∏—Ü–µ –æ—Ç –µ–¥–Ω–æ—Ç–æ –∏–ª–∏ –¥–≤–µ—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ—Ç–æ –µ –Ω–µ–≤—ä–∑–º–æ–∂–Ω–æ.")
# --- END OF FILE app/face_comparison.py ---
