# --- START OF FILE app/language_model_chat.py ---
import streamlit as st
import os
# –ò–º–ø–æ—Ä—Ç –Ω–∞ –∫–æ–Ω—Å—Ç–∞–Ω—Ç–∏ –æ—Ç config.py
from config import LLM_MODEL_DIR, LLM_MODEL_NAME

# –£–≤–µ—Ä–µ—Ç–µ —Å–µ, —á–µ llama_cpp –µ –∏–Ω—Å—Ç–∞–ª–∏—Ä–∞–Ω: pip install llama-cpp-python
try:
    from llama_cpp import Llama
    LLAMA_CPP_AVAILABLE = True
except ImportError:
    LLAMA_CPP_AVAILABLE = False

# –ö–æ–Ω—Å—Ç—Ä—É–∏—Ä–∞–Ω–µ –Ω–∞ –ø—ä—Ç—è –¥–æ –º–æ–¥–µ–ª–∞.
# main.py —Å–µ —Å—Ç–∞—Ä—Ç–∏—Ä–∞ –æ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è—Ç–∞ *–Ω–∞–¥* app/,
# —Ç–∞–∫–∞ —á–µ –ø—ä—Ç—è—Ç –æ—Ç—Ç–∞–º –¥–æ –º–æ–¥–µ–ª–∞ —â–µ –±—ä–¥–µ 'app/models/MODEL_NAME'
RELATIVE_MODEL_PATH_FROM_ROOT = os.path.join(
    "app", LLM_MODEL_DIR, LLM_MODEL_NAME)


def check_model_availability():
    """–ü—Ä–æ–≤–µ—Ä—è–≤–∞ –¥–∞–ª–∏ –º–æ–¥–µ–ª—ä—Ç —Å—ä—â–µ—Å—Ç–≤—É–≤–∞ –Ω–∞ –æ—á–∞–∫–≤–∞–Ω–∏—è –ø—ä—Ç."""
    if not os.path.exists(RELATIVE_MODEL_PATH_FROM_ROOT):
        st.error(
            f"‚ùå –ú–æ–¥–µ–ª—ä—Ç '{LLM_MODEL_NAME}' –ª–∏–ø—Å–≤–∞! –û—á–∞–∫–≤–∞ —Å–µ –¥–∞ –±—ä–¥–µ –≤ '{RELATIVE_MODEL_PATH_FROM_ROOT}'. "
            f"–°–≤–∞–ª–∏ –≥–æ –æ—Ç: https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf "
            f"–∏ –≥–æ –ø–æ—Å—Ç–∞–≤–∏ –≤ –ø–æ–¥–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è '{os.path.join('app', LLM_MODEL_DIR)}'."
        )
        return False
    return True


@st.cache_resource
def load_llm_model():
    """–ó–∞—Ä–µ–∂–¥–∞ –∏ –∫–µ—à–∏—Ä–∞ LLM –º–æ–¥–µ–ª–∞."""
    st.info(
        f"–ó–∞—Ä–µ–∂–¥–∞–Ω–µ –Ω–∞ LLM –º–æ–¥–µ–ª '{LLM_MODEL_NAME}'... –¢–æ–≤–∞ –º–æ–∂–µ –¥–∞ –æ—Ç–Ω–µ–º–µ –∏–∑–≤–µ—Å—Ç–Ω–æ –≤—Ä–µ–º–µ.")
    try:
        llm = Llama(
            model_path=RELATIVE_MODEL_PATH_FROM_ROOT,
            n_ctx=1024,
            # –ó–ê–î–ê–î–ï–ù–û –ù–ê 0 –ó–ê CPU –ü–û –ü–û–î–†–ê–ó–ë–ò–†–ê–ù–ï. –ü—Ä–æ–º–µ–Ω–µ—Ç–µ –∞–∫–æ –∏–º–∞—Ç–µ GPU –∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä–∞–Ω llama-cpp-python.
            n_gpu_layers=0,
            n_threads=6,
            verbose=False
        )
        st.success(f"LLM –º–æ–¥–µ–ª '{LLM_MODEL_NAME}' –µ –∑–∞—Ä–µ–¥–µ–Ω —É—Å–ø–µ—à–Ω–æ.")
        return llm
    except Exception as e:
        st.error(f"–ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –∑–∞—Ä–µ–∂–¥–∞–Ω–µ –Ω–∞ LLM –º–æ–¥–µ–ª–∞: {e}")
        st.error(
            "–£–≤–µ—Ä–µ—Ç–µ —Å–µ, —á–µ –∏–º–∞—Ç–µ –∏–Ω—Å—Ç–∞–ª–∏—Ä–∞–Ω `llama-cpp-python` (`pip install llama-cpp-python`).")
        st.error(
            "–ê–∫–æ –∏–∑–ø–æ–ª–∑–≤–∞—Ç–µ GPU (n_gpu_layers > 0), —É–≤–µ—Ä–µ—Ç–µ —Å–µ, —á–µ –∫–æ–º–ø–∏–ª–∞—Ü–∏—è—Ç–∞ –Ω–∞ llama-cpp-python –µ —Å GPU –ø–æ–¥–¥—Ä—ä–∂–∫–∞.")
        return None


# –ü—Ä–µ–∏–º–µ–Ω—É–≤–∞—Ö prompt –Ω–∞ current_user_prompt –∑–∞ —è—Å–Ω–æ—Ç–∞
def generate_llm_response(llm_instance, current_user_prompt):
    """–ì–µ–Ω–µ—Ä–∏—Ä–∞ –æ—Ç–≥–æ–≤–æ—Ä –æ—Ç LLM –≤—ä–∑ –æ—Å–Ω–æ–≤–∞ –Ω–∞ –∏—Å—Ç–æ—Ä–∏—è—Ç–∞ –Ω–∞ —á–∞—Ç–∞ –∏ —Ç–µ–∫—É—â–∏—è –ø—Ä–æ–º–ø—Ç."""
    if llm_instance is None:
        st.error("LLM –º–æ–¥–µ–ª—ä—Ç –Ω–µ –µ –∑–∞—Ä–µ–¥–µ–Ω, –Ω–µ –º–æ–≥–∞ –¥–∞ –≥–µ–Ω–µ—Ä–∏—Ä–∞–º –æ—Ç–≥–æ–≤–æ—Ä.")
        return None
    try:
        # –ò–∑–≥—Ä–∞–∂–¥–∞–Ω–µ –Ω–∞ –∏—Å—Ç–æ—Ä–∏—è—Ç–∞ –Ω–∞ —á–∞—Ç–∞ –∑–∞ –º–æ–¥–µ–ª–∞ –æ—Ç st.session_state
        # st.session_state[session_messages_key] –≤–µ—á–µ —Å—ä–¥—ä—Ä–∂–∞ –ø–æ—Å–ª–µ–¥–Ω–∏—è user_prompt
        chat_history_for_model = []
        # –ö–ª—é—á, –∏–∑–ø–æ–ª–∑–≤–∞–Ω –≤ render_page
        session_messages_key = f"llm_messages_{LLM_MODEL_NAME}"

        # –í–∫–ª—é—á–≤–∞–º–µ –≤—Å–∏—á–∫–∏ —Å—ä–æ–±—â–µ–Ω–∏—è –¥–æ –º–æ–º–µ–Ω—Ç–∞, –≤–∫–ª—é—á–∏—Ç–µ–ª–Ω–æ –ø–æ—Å–ª–µ–¥–Ω–∏—è user_prompt
        for msg in st.session_state.get(session_messages_key, []):
            chat_history_for_model.append(
                {"role": msg["role"], "content": msg["content"]})

        if not chat_history_for_model or chat_history_for_model[-1]["role"] != "user":
            # –¢–æ–≤–∞ –Ω–µ –±–∏ —Ç—Ä—è–±–≤–∞–ª–æ –¥–∞ —Å–µ —Å–ª—É—á–∏, –∞–∫–æ –ª–æ–≥–∏–∫–∞—Ç–∞ –≤ render_page –µ –ø—Ä–∞–≤–∏–ª–Ω–∞
            st.warning(
                "–ò—Å—Ç–æ—Ä–∏—è—Ç–∞ –Ω–∞ —á–∞—Ç–∞ –∏–∑–≥–ª–µ–∂–¥–∞ –Ω–µ–ø—ä–ª–Ω–∞ –ø—Ä–µ–¥–∏ –∏–∑–≤–∏–∫–≤–∞–Ω–µ –Ω–∞ LLM.")
            return None

        st.info("ü§ñ –ì–µ–Ω–µ—Ä–∏—Ä–∞–Ω–µ –Ω–∞ –æ—Ç–≥–æ–≤–æ—Ä –æ—Ç LLM...")
        response = llm_instance.create_chat_completion(
            messages=chat_history_for_model,
            temperature=0.7,
            max_tokens=350,  # –£–≤–µ–ª–∏—á–µ–Ω–æ –º–∞–ª–∫–æ
            stream=False
        )

        if response and 'choices' in response and len(response['choices']) > 0:
            ai_content = response['choices'][0]['message']['content']
            return ai_content.strip()
        else:
            st.warning("LLM –Ω–µ –≤—ä—Ä–Ω–∞ –æ—á–∞–∫–≤–∞–Ω –æ—Ç–≥–æ–≤–æ—Ä.")
            # st.json(response) # –ó–∞ –¥–µ–±—ä–≥, –∞–∫–æ response –Ω–µ –µ –∫–∞–∫–≤–æ—Ç–æ –æ—á–∞–∫–≤–∞–º–µ
            return None
    except Exception as e:
        st.error(f"–ì—Ä–µ—à–∫–∞ –ø–æ –≤—Ä–µ–º–µ –Ω–∞ –≥–µ–Ω–µ—Ä–∏—Ä–∞–Ω–µ –Ω–∞ –æ—Ç–≥–æ–≤–æ—Ä –æ—Ç LLM: {e}")
        # import traceback
        # st.error(traceback.format_exc()) # –ó–∞ –ø–æ-–¥–µ—Ç–∞–π–ª–µ–Ω traceback –ø—Ä–∏ –¥–µ–±—ä–≥
        return None


def render_page():
    # –ü–æ-–∫—Ä–∞—Ç–∫–æ –∏–º–µ –Ω–∞ –º–æ–¥–µ–ª–∞ –∑–∞ –∑–∞–≥–ª–∞–≤–∏–µ
    st.header(f"üí¨ –ß–∞—Ç —Å {LLM_MODEL_NAME.split('-')[0]}")

    if not LLAMA_CPP_AVAILABLE:
        st.error(
            "–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞—Ç–∞ `llama-cpp-python` –Ω–µ –µ –Ω–∞–º–µ—Ä–µ–Ω–∞. –ú–æ–ª—è, –∏–Ω—Å—Ç–∞–ª–∏—Ä–∞–π—Ç–µ —è: `pip install llama-cpp-python`")
        st.stop()

    if not check_model_availability():
        st.stop()

    llm_instance = load_llm_model()

    if llm_instance is None:
        st.error(
            "LLM –ú–æ–¥–µ–ª—ä—Ç –Ω–µ –º–æ–∂–∞ –¥–∞ –±—ä–¥–µ –∑–∞—Ä–µ–¥–µ–Ω. –ß–∞—Ç —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–Ω–æ—Å—Ç—Ç–∞ –Ω–µ –µ –¥–æ—Å—Ç—ä–ø–Ω–∞.")
        st.stop()

    session_messages_key = f"llm_messages_{LLM_MODEL_NAME}"
    if session_messages_key not in st.session_state:
        st.session_state[session_messages_key] = []
        # –ü—Ä–∏–º–µ—Ä–Ω–æ –ø—ä—Ä–≤–æ —Å—ä–æ–±—â–µ–Ω–∏–µ –æ—Ç –∞—Å–∏—Å—Ç–µ–Ω—Ç–∞, –∞–∫–æ –µ –Ω—É–∂–Ω–æ
        # st.session_state[session_messages_key].append(
        #     {"role": "assistant", "content": "–ó–¥—Ä–∞–≤–µ–π—Ç–µ! –ö–∞–∫ –º–æ–≥–∞ –¥–∞ –≤–∏ –ø–æ–º–æ–≥–Ω–∞ –¥–Ω–µ—Å?"}
        # )

    # –ü–æ–∫–∞–∑–≤–∞–Ω–µ –Ω–∞ —Å—ä—â–µ—Å—Ç–≤—É–≤–∞—â–∏—Ç–µ —Å—ä–æ–±—â–µ–Ω–∏—è
    for message in st.session_state[session_messages_key]:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if user_prompt := st.chat_input("–ù–∞–ø–∏—à–µ—Ç–µ –≤–∞—à–µ—Ç–æ —Å—ä–æ–±—â–µ–Ω–∏–µ..."):
        st.session_state[session_messages_key].append(
            {"role": "user", "content": user_prompt})
        with st.chat_message("user"):  # –ü–æ–∫–∞–∑–≤–∞–º–µ —Å—ä–æ–±—â–µ–Ω–∏–µ—Ç–æ –Ω–∞ –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—è –≤–µ–¥–Ω–∞–≥–∞
            st.markdown(user_prompt)

        # –ü–æ–¥–≥–æ—Ç–≤—è–º–µ –º—è—Å—Ç–æ –∑–∞ –æ—Ç–≥–æ–≤–æ—Ä–∞ –Ω–∞ –∞—Å–∏—Å—Ç–µ–Ω—Ç–∞
        with st.chat_message("assistant"):
            message_placeholder = st.empty()  # –ü–ª–µ–π—Å—Ö–æ–ª–¥—ä—Ä –∑–∞ —Å—Ç—Ä–∏–π–º–∏–Ω–≥ –∏–ª–∏ –∑–∞ "–º–∏—Å–ª—è..."
            message_placeholder.markdown("ü§ñ –ú–∏—Å–ª—è...")

            ai_response_content = generate_llm_response(
                llm_instance, user_prompt)

            if ai_response_content:
                message_placeholder.markdown(
                    ai_response_content)  # –ü–æ–∫–∞–∑–≤–∞–º–µ –æ—Ç–≥–æ–≤–æ—Ä–∞
                st.session_state[session_messages_key].append(
                    {"role": "assistant", "content": ai_response_content})
            else:
                message_placeholder.warning(
                    "–ù–µ –ø–æ–ª—É—á–∏—Ö –æ—Ç–≥–æ–≤–æ—Ä –æ—Ç –∞—Å–∏—Å—Ç–µ–Ω—Ç–∞ –∏–ª–∏ –≤—ä–∑–Ω–∏–∫–Ω–∞ –≥—Ä–µ—à–∫–∞.")
                # –ê–∫–æ –∏—Å–∫–∞–º–µ –¥–∞ –ø—Ä–µ–º–∞—Ö–Ω–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏—è user prompt –ø—Ä–∏ –≥—Ä–µ—à–∫–∞:
                # if st.session_state[session_messages_key][-1]["role"] == "user":
                #     st.session_state[session_messages_key].pop()

        # st.rerun() # –û–±–∏–∫–Ω–æ–≤–µ–Ω–æ –Ω–µ –µ –Ω—É–∂–µ–Ω —Å st.chat_input, —Ç—ä–π –∫–∞—Ç–æ —Ç–æ–π –ø—Ä–µ–¥–∏–∑–≤–∏–∫–≤–∞ –ø—Ä–µ–∑–∞—Ä–µ–∂–¥–∞–Ω–µ.
        # –ê–∫–æ –∏–º–∞ –ø—Ä–æ–±–ª–µ–º–∏ —Å—ä—Å —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è—Ç–∞ –Ω–∞ —Å—ä—Å—Ç–æ—è–Ω–∏–µ—Ç–æ, –º–æ–∂–µ –¥–∞ —Å–µ –Ω–∞–ª–æ–∂–∏.
