# --- START OF FILE app/face_analysis_image.py ---
import streamlit as st
import cv2
import numpy as np
from deepface import DeepFace
from utils import resize_image_for_display  # –ò–º–ø–æ—Ä—Ç –æ—Ç utils.py
# MAX_DISPLAY_DIM —â–µ —Å–µ –ø–æ–¥–∞–¥–µ –∫–∞—Ç–æ –∞—Ä–≥—É–º–µ–Ω—Ç –æ—Ç main.py


def render_page(deepface_models_loaded, MAX_DISPLAY_DIM):
    st.header("1. –ê–Ω–∞–ª–∏–∑ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (–í—ä–∑—Ä–∞—Å—Ç, –ü–æ–ª, –ï–º–æ—Ü–∏—è)")
    st.write("–ö–∞—á–µ—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –∑–∞ –¥–∞ –∞–Ω–∞–ª–∏–∑–∏—Ä–∞—Ç–µ –ª–∏—Ü–∞—Ç–∞ –∑–∞ –≤—ä–∑—Ä–∞—Å—Ç, –µ–º–æ—Ü–∏—è –∏ –ø–æ–ª, –∏–∑–ø–æ–ª–∑–≤–∞–π–∫–∏ DeepFace.")

    if not deepface_models_loaded:
        st.error("DeepFace –º–æ–¥–µ–ª–∏—Ç–µ –Ω–µ —Å–∞ –∑–∞—Ä–µ–¥–µ–Ω–∏. –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–Ω–æ—Å—Ç—Ç–∞ –Ω–µ –µ –¥–æ—Å—Ç—ä–ø–Ω–∞.")
        st.stop()

    uploaded_img_file = st.file_uploader(
        # –£–Ω–∏–∫–∞–ª–µ–Ω –∫–ª—é—á –∑–∞ file_uploader
        "–ò–∑–±–µ—Ä–µ—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...", type=["jpg", "jpeg", "png"], key="deepface_image_uploader_module"
    )

    if uploaded_img_file is not None:
        file_bytes = np.asarray(
            bytearray(uploaded_img_file.read()), dtype=np.uint8)
        img_cv2_original_bgr = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)

        if img_cv2_original_bgr is None:
            st.error(
                "–ù–µ –º–æ–∂–∞—Ö –¥–∞ –ø—Ä–æ—á–µ—Ç–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ—Ç–æ. –ú–æ–ª—è, –æ–ø–∏—Ç–∞–π—Ç–µ —Å –¥—Ä—É–≥ —Ñ–∞–π–ª.")
        else:
            st.subheader("–û—Ä–∏–≥–∏–Ω–∞–ª–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ:")
            img_display_resized_bgr = resize_image_for_display(
                img_cv2_original_bgr, MAX_DISPLAY_DIM)
            img_display_resized_rgb = cv2.cvtColor(
                img_display_resized_bgr, cv2.COLOR_BGR2RGB)
            st.image(img_display_resized_rgb,
                     caption="–û—Ä–∏–≥–∏–Ω–∞–ª–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (–æ—Ä–∞–∑–º–µ—Ä–µ–Ω–æ)", use_column_width='auto')

            if st.button("üöÄ –ê–Ω–∞–ª–∏–∑–∏—Ä–∞–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ—Ç–æ (DeepFace)", key="analyze_image_deepface_btn"):
                with st.spinner("–ê–Ω–∞–ª–∏–∑–∏—Ä–∞–Ω–µ –Ω–∞ –ª–∏—Ü–∞—Ç–∞ —Å DeepFace..."):
                    try:
                        face_analysis_results = DeepFace.analyze(
                            img_path=img_cv2_original_bgr.copy(),  # –ò–∑–ø—Ä–∞—â–∞–º–µ –∫–æ–ø–∏–µ
                            actions=['age', 'gender', 'emotion'],
                            enforce_detection=False,
                            detector_backend='opencv',  # –ú–æ–∂–µ –¥–∞ —Å—Ç–∞–Ω–µ –∏–∑–±–∏—Ä–∞–µ–º–æ
                            silent=True
                        )
                    except Exception as e:
                        st.error(f"–í—ä–∑–Ω–∏–∫–Ω–∞ –≥—Ä–µ—à–∫–∞ –ø—Ä–∏ DeepFace –∞–Ω–∞–ª–∏–∑: {e}")
                        face_analysis_results = []  # –ü—Ä–∞–∑–µ–Ω —Å–ø–∏—Å—ä–∫ –ø—Ä–∏ –≥—Ä–µ—à–∫–∞

                img_cv2_annotated_bgr = img_cv2_original_bgr.copy()

                if not face_analysis_results or not isinstance(face_analysis_results, list):
                    # –¢–æ–∑–∏ —Å–ª—É—á–∞–π –µ –∞–∫–æ DeepFace –≤—ä—Ä–Ω–µ –Ω–µ—â–æ –Ω–µ–æ—á–∞–∫–≤–∞–Ω–æ (–Ω–µ —Å–ø–∏—Å—ä–∫)
                    st.info("–ê–Ω–∞–ª–∏–∑—ä—Ç –Ω–µ –≤—ä—Ä–Ω–∞ –≤–∞–ª–∏–¥–Ω–∏ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏.")
                else:
                    num_faces_detected = 0
                    for i, face_result in enumerate(face_analysis_results):
                        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–ª–∏ 'region' —Å—ä—â–µ—Å—Ç–≤—É–≤–∞ –∏ –¥–∞–ª–∏ W/H —Å–∞ –≤–∞–ª–∏–¥–Ω–∏
                        # DeepFace —Å enforce_detection=False –≤—Ä—ä—â–∞ 1 –∑–∞–ø–∏—Å —Å w=0, h=0 –∞–∫–æ –Ω—è–º–∞ –ª–∏—Ü–µ
                        if 'region' not in face_result or face_result['region']['w'] == 0 or face_result['region']['h'] == 0:
                            # –ü—Ä–æ–ø—É—Å–∫–∞–º–µ, –∞–∫–æ –Ω—è–º–∞ –≤–∞–ª–∏–¥–µ–Ω —Ä–µ–≥–∏–æ–Ω (—Ç.–µ. –Ω–µ –µ –∑–∞—Å–µ—á–µ–Ω–æ –ª–∏—Ü–µ)
                            continue

                        num_faces_detected += 1
                        st.write(f"---")
                        st.write(f"#### –õ–∏—Ü–µ {num_faces_detected}:")

                        age = face_result.get('age', 'N/A')

                        dominant_gender_map = face_result.get('gender', {})
                        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–ª–∏ 'gender' –µ —Ä–µ—á–Ω–∏–∫ –∏ –Ω–µ –µ –ø—Ä–∞–∑–µ–Ω
                        if isinstance(dominant_gender_map, dict) and dominant_gender_map:
                            dominant_gender = max(
                                dominant_gender_map, key=dominant_gender_map.get)
                            gender_confidence = dominant_gender_map[dominant_gender]
                        else:  # –ê–∫–æ DeepFace –≤—ä—Ä–Ω–µ –¥–∏—Ä–µ–∫—Ç–Ω–æ dominant_gender –∏–ª–∏ –ø—Ä–∞–∑–µ–Ω —Ä–µ—á–Ω–∏–∫
                            dominant_gender = face_result.get(
                                'dominant_gender', 'N/A')
                            gender_confidence = 0

                        dominant_emotion_map = face_result.get('emotion', {})
                        if isinstance(dominant_emotion_map, dict) and dominant_emotion_map:
                            dominant_emotion = max(
                                dominant_emotion_map, key=dominant_emotion_map.get)
                            emotion_confidence = dominant_emotion_map[dominant_emotion]
                        else:
                            dominant_emotion = face_result.get(
                                'dominant_emotion', 'N/A')
                            emotion_confidence = 0

                        region = face_result['region']

                        st.write(f"- **–í—ä–∑—Ä–∞—Å—Ç:** {age}")
                        st.write(
                            f"- **–ü–æ–ª:** {dominant_gender} ({gender_confidence:.2f}%)" if gender_confidence > 0 else f"- **–ü–æ–ª:** {dominant_gender}")
                        st.write(
                            f"- **–ï–º–æ—Ü–∏—è:** {dominant_emotion} ({emotion_confidence:.2f}%)" if emotion_confidence > 0 else f"- **–ï–º–æ—Ü–∏—è:** {dominant_emotion}")

                        x, y, w, h = region['x'], region['y'], region['w'], region['h']
                        cv2.rectangle(img_cv2_annotated_bgr,
                                      (x, y), (x+w, y+h), (0, 255, 0), 2)
                        text_gender_char = dominant_gender[0].upper(
                        ) if dominant_gender and isinstance(dominant_gender, str) and dominant_gender != "N/A" else "N"
                        text = f"A:{age} G:{text_gender_char} E:{dominant_emotion}"
                        cv2.putText(img_cv2_annotated_bgr, text, (x, y - 10),
                                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

                    if num_faces_detected > 0:
                        st.subheader("–ê–Ω–æ—Ç–∏—Ä–∞–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ:")
                        annotated_display_resized_bgr = resize_image_for_display(
                            img_cv2_annotated_bgr, MAX_DISPLAY_DIM)
                        annotated_display_resized_rgb = cv2.cvtColor(
                            annotated_display_resized_bgr, cv2.COLOR_BGR2RGB)
                        st.image(annotated_display_resized_rgb,
                                 caption=f"–ê–Ω–∞–ª–∏–∑–∏—Ä–∞–Ω–∏ –ª–∏—Ü–∞: {num_faces_detected}", use_column_width='auto')
                    else:  # –ê–∫–æ num_faces_detected –µ 0 —Å–ª–µ–¥ –æ–±—Ö–æ–∂–¥–∞–Ω–µ –Ω–∞ –≤—Å–∏—á–∫–∏ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏
                        st.info(
                            "–ù–µ –±—è—Ö–∞ –æ—Ç–∫—Ä–∏—Ç–∏ –ª–∏—Ü–∞ –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ—Ç–æ, –∫–æ–∏—Ç–æ –¥–∞ –±—ä–¥–∞—Ç –∞–Ω–∞–ª–∏–∑–∏—Ä–∞–Ω–∏.")
# --- END OF FILE app/face_analysis_image.py ---
