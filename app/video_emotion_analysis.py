import streamlit as st
import cv2
import numpy as np
from deepface import DeepFace
import os
import tempfile
import time
import traceback
# –ò–º–ø–æ—Ä—Ç –Ω–∞ –∫–æ–Ω—Å—Ç–∞–Ω—Ç–∏ –æ—Ç config.py, –∫–æ–∏—Ç–æ –≤–µ—á–µ —â–µ –≤–∫–ª—é—á–≤–∞—Ç –ª–æ–≥–∏–∫–∞—Ç–∞ –∑–∞ –∏–∑–±–æ—Ä –Ω–∞ –∫–æ–¥–µ–∫
from config import DEFAULT_VIDEO_FPS, VIDEO_OUTPUT_CODEC, VIDEO_OUTPUT_SUFFIX, VIDEO_MIME_TYPE, TEMP_FILE_SUFFIX


def render_page(deepface_models_loaded):
    st.header("3. –ê–Ω–∞–ª–∏–∑ –Ω–∞ –µ–º–æ—Ü–∏–∏ –≤—ä–≤ –≤–∏–¥–µ–æ (DeepFace)")
    if not deepface_models_loaded:
        st.error("DeepFace –º–æ–¥–µ–ª–∏—Ç–µ –Ω–µ —Å–∞ –∑–∞—Ä–µ–¥–µ–Ω–∏. –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–Ω–æ—Å—Ç—Ç–∞ –Ω–µ –µ –¥–æ—Å—Ç—ä–ø–Ω–∞.")
        st.stop()

    uploaded_video_file = st.file_uploader(
        "–ò–∑–±–µ—Ä–µ—Ç–µ –≤–∏–¥–µ–æ —Ñ–∞–π–ª (.mp4, .avi, .mov, .mkv)...", type=["mp4", "avi", "mov", "mkv"], key="deepface_video_uploader_module"
    )

    frame_skip_file = st.sidebar.slider(
        "–ü—Ä–æ–ø—É—Å–∫–∞–π –∫–∞–¥—Ä–∏ –∑–∞ –∞–Ω–∞–ª–∏–∑ (—Ñ–∞–π–ª):", 0, 10, 1, key="video_frame_skip_file_module_active")
    detector_backend_video_file = st.sidebar.selectbox(
        "DeepFace –¥–µ—Ç–µ–∫—Ç–æ—Ä –∑–∞ –≤–∏–¥–µ–æ (—Ñ–∞–π–ª):",
        ('opencv', 'ssd', 'mtcnn', 'retinaface', 'yunet'), index=0, key="video_detector_file_module_active")

    if uploaded_video_file is not None:
        current_video_id = f"{uploaded_video_file.name}_{uploaded_video_file.size}"
        input_video_session_key = f"temp_video_path_{current_video_id}"
        # –î–æ–±–∞–≤—è–º–µ –∫–æ–¥–µ–∫–∞ –∫—ä–º –∫–ª—é—á–∞
        output_video_display_cache_key = f"cached_output_video_path_{current_video_id}_{detector_backend_video_file}_{frame_skip_file}_{VIDEO_OUTPUT_CODEC}"

        if input_video_session_key not in st.session_state or \
           not os.path.exists(st.session_state[input_video_session_key]):
            try:
                # –£–≤–µ—Ä—è–≤–∞–º–µ —Å–µ, —á–µ —Å—Ç–∞—Ä–∏—è—Ç —Ñ–∞–π–ª —Å–µ –∏–∑—Ç—Ä–∏–≤–∞, –∞–∫–æ –∫–ª—é—á—ä—Ç —Å—ä—â–µ—Å—Ç–≤—É–≤–∞, –Ω–æ —Ñ–∞–π–ª—ä—Ç –Ω–µ
                if input_video_session_key in st.session_state and st.session_state.get(input_video_session_key):
                    if os.path.exists(st.session_state[input_video_session_key]):
                        try:
                            os.remove(
                                st.session_state[input_video_session_key])
                        except OSError:
                            pass  # –ò–≥–Ω–æ—Ä–∏—Ä–∞–º–µ –≥—Ä–µ—à–∫–∞ –ø—Ä–∏ –∏–∑—Ç—Ä–∏–≤–∞–Ω–µ
                    del st.session_state[input_video_session_key]

                with tempfile.NamedTemporaryFile(delete=False, suffix=f".{uploaded_video_file.name.split('.')[-1]}") as tfile:
                    tfile.write(uploaded_video_file.read())
                    st.session_state[input_video_session_key] = tfile.name
                # st.caption(f"–í—Ö–æ–¥–Ω–æ—Ç–æ –≤–∏–¥–µ–æ –µ –∑–∞–ø–∞–∑–µ–Ω–æ –≤—Ä–µ–º–µ–Ω–Ω–æ –≤: {st.session_state[input_video_session_key]}") # –ú–æ–∂–µ –¥–∞ —Å–µ –º–∞—Ö–Ω–µ –∑–∞ –ø–æ-—á–∏—Å—Ç –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
            except Exception as e:
                st.error(f"–ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å –Ω–∞ –∫–∞—á–µ–Ω–∏—è –≤–∏–¥–µ–æ —Ñ–∞–π–ª: {e}")
                st.stop()

        temp_video_path = st.session_state[input_video_session_key]

        st.subheader("–û—Ä–∏–≥–∏–Ω–∞–ª–Ω–æ –≤–∏–¥–µ–æ:")
        col_orig_video, _ = st.columns([2, 1])
        with col_orig_video:
            if os.path.exists(temp_video_path):
                st.video(temp_video_path)
            else:
                st.warning(
                    "–û—Ä–∏–≥–∏–Ω–∞–ª–Ω–∏—è—Ç –≤–∏–¥–µ–æ —Ñ–∞–π–ª –Ω–µ –µ –Ω–∞–º–µ—Ä–µ–Ω. –ú–æ–ª—è, –∫–∞—á–µ—Ç–µ –≥–æ –æ—Ç–Ω–æ–≤–æ.")
        # st.caption("–û—Ä–∏–≥–∏–Ω–∞–ª–Ω–æ—Ç–æ –≤–∏–¥–µ–æ —Å–µ –ø–æ–∫–∞–∑–≤–∞ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –æ—Ä–∞–∑–º–µ—Ä—è–≤–∞–Ω–µ.")

        if st.button("üöÄ –ê–Ω–∞–ª–∏–∑–∏—Ä–∞–π –≤–∏–¥–µ–æ—Ç–æ (DeepFace)", key="analyze_video_deepface_btn"):
            if not os.path.exists(temp_video_path):
                st.error(
                    "–ì—Ä–µ—à–∫–∞: –í—Ö–æ–¥–Ω–∏—è—Ç –≤–∏–¥–µ–æ —Ñ–∞–π–ª –Ω–µ –µ –Ω–∞–º–µ—Ä–µ–Ω. –ú–æ–ª—è, –∫–∞—á–µ—Ç–µ –≥–æ –æ—Ç–Ω–æ–≤–æ.")
                st.stop()

            base_name, _ = os.path.splitext(uploaded_video_file.name)
            # –ò–º–µ—Ç–æ –Ω–∞ —Ñ–∞–π–ª–∞ –∑–∞ —Å–≤–∞–ª—è–Ω–µ –≤–µ—á–µ –∏–∑–ø–æ–ª–∑–≤–∞ VIDEO_OUTPUT_SUFFIX –æ—Ç config.py
            output_video_filename_for_download = f"{base_name}{VIDEO_OUTPUT_SUFFIX}"

            current_run_output_video_path = None
            try:
                # –°—É—Ñ–∏–∫—Å—ä—Ç –Ω–∞ –≤—Ä–µ–º–µ–Ω–Ω–∏—è —Ñ–∞–π–ª –≤–µ—á–µ –∏–¥–≤–∞ –æ—Ç config.py (TEMP_FILE_SUFFIX)
                with tempfile.NamedTemporaryFile(delete=False, suffix=TEMP_FILE_SUFFIX) as t_out:
                    current_run_output_video_path = t_out.name
                st.info(
                    f"–û–±—Ä–∞–±–æ—Ç–∫–∞—Ç–∞ —â–µ –∑–∞–ø–∏—à–µ —Ä–µ–∑—É–ª—Ç–∞—Ç–∞ –≤ –Ω–æ–≤ –≤—Ä–µ–º–µ–Ω–µ–Ω —Ñ–∞–π–ª: {current_run_output_video_path} (–ö–æ–¥–µ–∫: {VIDEO_OUTPUT_CODEC})")
            except Exception as e_tempfile:
                st.error(
                    f"–ì—Ä–µ—à–∫–∞ –ø—Ä–∏ —Å—ä–∑–¥–∞–≤–∞–Ω–µ –Ω–∞ –≤—Ä–µ–º–µ–Ω–µ–Ω –∏–∑—Ö–æ–¥–µ–Ω —Ñ–∞–π–ª: {e_tempfile}")
                st.stop()

            if not current_run_output_video_path:  # –î–≤–æ–π–Ω–∞ –ø—Ä–æ–≤–µ—Ä–∫–∞
                st.error("–ù–µ –º–æ–∂–∞ –¥–∞ —Å–µ —Å—ä–∑–¥–∞–¥–µ –≤—Ä–µ–º–µ–Ω–µ–Ω –∏–∑—Ö–æ–¥–µ–Ω —Ñ–∞–π–ª.")
                st.stop()

            cap = None
            out_writer = None
            analysis_successful = False

            try:
                cap = cv2.VideoCapture(temp_video_path)
                if not cap.isOpened():
                    st.error(
                        f"–ì—Ä–µ—à–∫–∞: –ù–µ –º–æ–∂–µ –¥–∞ —Å–µ –æ—Ç–≤–æ—Ä–∏ –≤–∏–¥–µ–æ —Ñ–∞–π–ª—ä—Ç: {uploaded_video_file.name}")
                    st.stop()

                frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                fps = cap.get(cv2.CAP_PROP_FPS)
                if not (fps and 0 < fps < 200):
                    st.warning(
                        f"–ù–µ–≤–∞–ª–∏–¥–Ω–∞ FPS —Å—Ç–æ–π–Ω–æ—Å—Ç ({fps}) –æ—Ç –≤–∏–¥–µ–æ—Ç–æ. –ó–∞–¥–∞–≤–∞–º {DEFAULT_VIDEO_FPS} FPS.")
                    fps = DEFAULT_VIDEO_FPS

                fourcc = cv2.VideoWriter_fourcc(*VIDEO_OUTPUT_CODEC)
                out_writer = cv2.VideoWriter(
                    current_run_output_video_path, fourcc, fps, (frame_width, frame_height))

                if not out_writer.isOpened():
                    st.error(
                        f"–ì—Ä–µ—à–∫–∞: –ù–µ –º–æ–∂–µ –¥–∞ —Å–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–∞ VideoWriter —Å –∫–æ–¥–µ–∫ '{VIDEO_OUTPUT_CODEC}'. –ü—Ä–æ–≤–µ—Ä–µ—Ç–µ –≤–∞—à–∞—Ç–∞ OpenCV/FFmpeg –∏–Ω—Å—Ç–∞–ª–∞—Ü–∏—è –∏ –Ω–∞–ª–∏—á–Ω–∏—Ç–µ –∫–æ–¥–µ—Ü–∏.")
                    if os.path.exists(current_run_output_video_path):
                        # –ò–∑—Ç—Ä–∏–≤–∞–º–µ –Ω–µ—É—Å–ø–µ—à–Ω–∏—è —Ñ–∞–π–ª
                        os.remove(current_run_output_video_path)
                    st.stop()

                # st.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞ –≤–∏–¥–µ–æ: {uploaded_video_file.name} ({frame_width}x{frame_height} @ {fps:.2f} FPS) —Å –¥–µ—Ç–µ–∫—Ç–æ—Ä '{detector_backend_video_file}'. –ö–æ–¥–µ–∫: {VIDEO_OUTPUT_CODEC}")
                progress_bar = st.progress(0)
                status_text = st.empty()
                percent_complete_text = st.empty()

                total_frames_prop = cap.get(cv2.CAP_PROP_FRAME_COUNT)
                total_frames = int(
                    total_frames_prop) if total_frames_prop > 0 else 0

                processed_frame_count_for_analysis = 0
                current_frame_num_read = 0
                emotions_summary = {}
                start_time = time.time()
                last_known_faces_data = []

                while cap.isOpened():
                    ret, frame_bgr = cap.read()
                    if not ret:
                        break

                    current_frame_num_read += 1
                    frame_to_write = frame_bgr.copy()

                    if current_frame_num_read % (frame_skip_file + 1) == 1:
                        processed_frame_count_for_analysis += 1
                        try:
                            results = DeepFace.analyze(frame_bgr.copy(), actions=['emotion'], enforce_detection=True,
                                                       detector_backend=detector_backend_video_file, silent=True)
                            current_faces_data = []
                            if isinstance(results, list) and len(results) > 0:
                                for result in results:
                                    if 'region' in result and result['region']['w'] > 0 and result['region']['h'] > 0:
                                        x, y, w, h = result['region']['x'], result['region'][
                                            'y'], result['region']['w'], result['region']['h']
                                        dominant_emotion_map = result.get(
                                            'emotion', {})
                                        if isinstance(dominant_emotion_map, dict) and dominant_emotion_map:
                                            emotion = max(
                                                dominant_emotion_map, key=dominant_emotion_map.get)
                                            confidence = dominant_emotion_map[emotion]
                                        else:
                                            emotion = result.get(
                                                'dominant_emotion', "N/A")
                                            confidence = 0.0
                                        emotions_summary[emotion] = emotions_summary.get(
                                            emotion, 0) + 1
                                        current_faces_data.append({'box': (
                                            x, y, w, h), 'text': f"{emotion} ({confidence:.2f}%)" if confidence > 0 else emotion})
                            last_known_faces_data = current_faces_data
                        except ValueError:
                            last_known_faces_data = []
                        except Exception as deepface_e:
                            st.warning(
                                f"DeepFace –≥—Ä–µ—à–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑ –Ω–∞ –∫–∞–¥—ä—Ä {current_frame_num_read}: {deepface_e}")
                            last_known_faces_data = []

                    if last_known_faces_data:
                        for face_data in last_known_faces_data:
                            x, y, w, h = face_data['box']
                            text = face_data['text']
                            cv2.rectangle(frame_to_write, (x, y),
                                          (x+w, y+h), (0, 255, 0), 2)
                            cv2.putText(frame_to_write, text, (x, y-10),
                                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                    out_writer.write(frame_to_write)

                    if total_frames > 0:
                        progress_val = int(
                            (current_frame_num_read / total_frames) * 100)
                        progress_bar.progress(min(progress_val, 100))
                        percent_complete_text.text(
                            f"{min(progress_val, 100)}% –∑–∞–≤—ä—Ä—à–µ–Ω–æ")

                end_time = time.time()
                progress_bar.empty()
                status_text.empty()
                percent_complete_text.empty()
                st.success(
                    f"–í–∏–¥–µ–æ –æ–±—Ä–∞–±–æ—Ç–∫–∞—Ç–∞ –ø—Ä–∏–∫–ª—é—á–∏ –∑–∞ {end_time - start_time:.2f} —Å–µ–∫—É–Ω–¥–∏.")
                st.info(
                    f"–û–±—â–æ –ø—Ä–æ—á–µ—Ç–µ–Ω–∏ –∫–∞–¥—Ä–∏: {current_frame_num_read}. –ê–Ω–∞–ª–∏–∑–∏—Ä–∞–Ω–∏: {processed_frame_count_for_analysis}")
                analysis_successful = True

            except Exception as e_video:
                st.error(
                    f"–í—ä–∑–Ω–∏–∫–Ω–∞ –Ω–µ–æ—á–∞–∫–≤–∞–Ω–∞ –≥—Ä–µ—à–∫–∞ –ø–æ –≤—Ä–µ–º–µ –Ω–∞ –≤–∏–¥–µ–æ –æ–±—Ä–∞–±–æ—Ç–∫–∞—Ç–∞: {e_video}")
                st.error(traceback.format_exc())
                analysis_successful = False
            finally:
                if cap is not None:
                    cap.release()
                if out_writer is not None:
                    out_writer.release()

            if analysis_successful and current_run_output_video_path and \
               os.path.exists(current_run_output_video_path) and \
               os.path.getsize(current_run_output_video_path) > 0:

                st.subheader("–û–±—Ä–∞–±–æ—Ç–µ–Ω–æ –≤–∏–¥–µ–æ (—Ç–æ–∫—É-—â–æ –≥–µ–Ω–µ—Ä–∏—Ä–∞–Ω–æ):")
                st.caption(
                    f"–§–∞–π–ª –∑–∞ –ø–æ–∫–∞–∑–≤–∞–Ω–µ: {current_run_output_video_path}, –†–∞–∑–º–µ—Ä: {os.path.getsize(current_run_output_video_path) / (1024*1024):.2f} MB")

                # –ò–∑—Ä–∏—á–Ω–∞ –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–µ–¥–∏ st.video
                if os.path.exists(current_run_output_video_path) and os.path.getsize(current_run_output_video_path) > 0:
                    col_proc_video, _ = st.columns([2, 1])
                    with col_proc_video:
                        st.video(current_run_output_video_path,
                                 format=VIDEO_MIME_TYPE)  # –ü–æ–¥–∞–≤–∞–º–µ MIME —Ç–∏–ø–∞

                    # –£—Å–ø–µ—à–Ω–æ –µ, –∑–∞–ø–∞–∑–≤–∞–º–µ –ø—ä—Ç—è –≤ —Å–µ—Å–∏—è—Ç–∞ –∑–∞ –∫–µ—à–∏—Ä–∞–Ω–µ –Ω–∞ –ø–æ–∫–∞–∑–≤–∞–Ω–µ—Ç–æ
                    if output_video_display_cache_key in st.session_state and \
                       st.session_state.get(output_video_display_cache_key) and \
                       os.path.exists(st.session_state[output_video_display_cache_key]) and \
                       st.session_state[output_video_display_cache_key] != current_run_output_video_path:
                        try:
                            os.remove(
                                st.session_state[output_video_display_cache_key])
                        except OSError:
                            pass
                    st.session_state[output_video_display_cache_key] = current_run_output_video_path

                    with open(current_run_output_video_path, 'rb') as video_file_for_download:
                        video_bytes_for_download = video_file_for_download.read()
                    st.download_button(label=f"üì• –°–≤–∞–ª–∏ –æ–±—Ä–∞–±–æ—Ç–µ–Ω–æ—Ç–æ –≤–∏–¥–µ–æ ({VIDEO_OUTPUT_CODEC.upper()})",
                                       data=video_bytes_for_download,
                                       file_name=output_video_filename_for_download,
                                       mime=VIDEO_MIME_TYPE,
                                       key=f"download_btn_current_{output_video_display_cache_key}")
                else:
                    st.error(
                        "–ì—Ä–µ—à–∫–∞: –ì–µ–Ω–µ—Ä–∏—Ä–∞–Ω–∏—è—Ç —Ñ–∞–π–ª –∏–∑–≥–ª–µ–∂–¥–∞ –Ω–µ–≤–∞–ª–∏–¥–µ–Ω –∏–ª–∏ –ø—Ä–∞–∑–µ–Ω —Ç–æ—á–Ω–æ –ø—Ä–µ–¥–∏ –ø–æ–∫–∞–∑–≤–∞–Ω–µ.")

            else:  # analysis_successful is False OR file is invalid
                st.error(
                    "–ù–µ—É—Å–ø–µ—à–Ω–æ –≥–µ–Ω–µ—Ä–∏—Ä–∞–Ω–µ –Ω–∞ –∏–∑—Ö–æ–¥–Ω–æ—Ç–æ –≤–∏–¥–µ–æ –∏–ª–∏ —Ñ–∞–π–ª—ä—Ç –µ –ø—Ä–∞–∑–µ–Ω/–Ω–µ–≤–∞–ª–∏–¥–µ–Ω.")
                if current_run_output_video_path and os.path.exists(current_run_output_video_path):
                    try:
                        os.remove(current_run_output_video_path)
                        st.info(
                            f"–ò–∑—Ç—Ä–∏—Ç –Ω–µ—É—Å–ø–µ—à–Ω–æ –≥–µ–Ω–µ—Ä–∏—Ä–∞–Ω —Ñ–∞–π–ª: {current_run_output_video_path}")
                    except OSError:
                        pass

            if emotions_summary and analysis_successful:
                st.subheader("–û–±–æ–±—â–µ–Ω–∏–µ –Ω–∞ –∑–∞—Å–µ—á–µ–Ω–∏—Ç–µ –¥–æ–º–∏–Ω–∏—Ä–∞—â–∏ –µ–º–æ—Ü–∏–∏:")
                sorted_emotions = dict(
                    sorted(emotions_summary.items(), key=lambda item: item[1], reverse=True))
                st.bar_chart(sorted_emotions)
            elif not analysis_successful:
                st.info(
                    "–û–±–æ–±—â–µ–Ω–∏–µ –Ω–∞ –µ–º–æ—Ü–∏–∏—Ç–µ –Ω–µ –µ –Ω–∞–ª–∏—á–Ω–æ –ø–æ—Ä–∞–¥–∏ –≥—Ä–µ—à–∫–∞ –≤ –æ–±—Ä–∞–±–æ—Ç–∫–∞—Ç–∞.")
            else:
                st.info("–ù–µ —Å–∞ –∑–∞—Å–µ—á–µ–Ω–∏ –µ–º–æ—Ü–∏–∏ –ø–æ –≤—Ä–µ–º–µ –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞—Ç–∞.")

        elif output_video_display_cache_key in st.session_state and \
                st.session_state.get(output_video_display_cache_key) and \
                os.path.exists(st.session_state[output_video_display_cache_key]) and \
                os.path.getsize(st.session_state[output_video_display_cache_key]) > 0:

            cached_video_path = st.session_state[output_video_display_cache_key]
            st.subheader("–ü—Ä–µ–¥–∏—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–µ–Ω–æ –≤–∏–¥–µ–æ (–∫–µ—à–∏—Ä–∞–Ω–æ):")
            st.caption(
                f"–ö–µ—à–∏—Ä–∞–Ω —Ñ–∞–π–ª: {cached_video_path}, –ö–æ–¥–µ–∫: {VIDEO_OUTPUT_CODEC.upper()}")

            base_name, _ = os.path.splitext(uploaded_video_file.name)
            output_video_filename_for_download = f"{base_name}{VIDEO_OUTPUT_SUFFIX}"

            col_cached_proc_video, _ = st.columns([2, 1])
            with col_cached_proc_video:
                st.video(cached_video_path, format=VIDEO_MIME_TYPE)

            try:
                with open(cached_video_path, 'rb') as video_file_for_download:
                    video_bytes_for_download = video_file_for_download.read()
                st.download_button(label=f"üì• –°–≤–∞–ª–∏ —Ç–æ–≤–∞ (–∫–µ—à–∏—Ä–∞–Ω–æ) –≤–∏–¥–µ–æ ({VIDEO_OUTPUT_CODEC.upper()})",
                                   data=video_bytes_for_download,
                                   file_name=output_video_filename_for_download,
                                   mime=VIDEO_MIME_TYPE,
                                   key=f"download_btn_cached_{output_video_display_cache_key}")
            except FileNotFoundError:
                st.error("–ö–µ—à–∏—Ä–∞–Ω–∏—è—Ç –≤–∏–¥–µ–æ —Ñ–∞–π–ª –Ω–µ –±–µ—à–µ –Ω–∞–º–µ—Ä–µ–Ω –∑–∞ —Å–≤–∞–ª—è–Ω–µ.")
            # –û–±–æ–±—â–µ–Ω–∏–µ—Ç–æ –Ω–∞ –µ–º–æ—Ü–∏–∏—Ç–µ –Ω–µ —Å–µ –ø–æ–∫–∞–∑–≤–∞ –∑–∞ –∫–µ—à–∏—Ä–∞–Ω–æ—Ç–æ –≤–∏–¥–µ–æ, —Ç—ä–π –∫–∞—Ç–æ –Ω–µ —Å–µ –ø–∞–∑–∏ –≤ —Å–µ—Å–∏—è—Ç–∞.
